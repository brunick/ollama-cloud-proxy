# Ollama Cloud Proxy

Dieser Proxy leitet Anfragen an die offizielle Ollama Cloud API (`https://ollama.com/api`) weiter. Er bietet intelligentes Load-Balancing, Key-Rotation und ein detailliertes Dashboard zur Ãœberwachung der Nutzung.

![Dashboard](assets/dashboard.png)

## Features

- **ğŸš€ Smart Load-Balancing**: Verteilt Anfragen automatisch auf verfÃ¼gbare API-Keys basierend auf der geringsten Nutzung in den letzten 2 Stunden.
- **ğŸ”„ Automatische Key-Rotation**: Erkennt `429 Too Many Requests` Fehler (Quota exceeded) und wiederholt den Request intern sofort mit einem anderen verfÃ¼gbaren Key.
- **ğŸ“Š Echtzeit-Dashboard**: Integriertes Web-Interface zur Ãœberwachung von Token-Verbrauch, Key-Status und Request-Logs.
- **ğŸ“ˆ Nutzungsstatistiken**:
  - Gesamt-Token-Counter (letzte 24h) mit stÃ¼ndlichem Sparkline-Graph.
  - Detaillierter Token-Usage-Graph mit konfigurierbaren Zeitfenstern (60m, 2h, 4h, 6h, 12h, 24h).
  - Gestapelte Ansicht nach Modellen und Summenlinie.
- **ğŸ›¡ï¸ Proxy Protection**: Optionaler `PROXY_AUTH_TOKEN`, um unbefugten Zugriff auf deinen Proxy zu verhindern.
- **ğŸŒ Timezone Support**: Alle Statistiken werden automatisch in der lokalen Zeitzone des Nutzers angezeigt (UTC-Backend).
- **ğŸ“ Request Logging**: Speichert Request-Bodies (komprimiert) fÃ¼r Debugging-Zwecke (einsehbar im Dashboard).

## Setup

1. **Konfiguration**:
   Erstelle eine `.env` Datei im Stammverzeichnis oder setze die Umgebungsvariablen direkt.

   ### Mehrere API-Keys (Rotation)
   Du kannst mehrere Keys Ã¼ber eine Konfigurationsdatei oder eine Umgebungsvariable angeben:

   **Option A: `config/config.yaml` (Empfohlen)**
   ```yaml
   keys:
     - "key_1"
     - "key_2"
     - "key_3"
   ```

   **Option B: Umgebungsvariable**
   ```env
   OLLAMA_API_KEYS=key1,key2,key3
   ```

   ### Weitere Optionen
   ```env
   PROXY_AUTH_TOKEN=ein_geheimes_passwort_fuer_lokal
   ALLOW_UNAUTHENTICATED_ACCESS=false # Wenn true, wird kein Token benÃ¶tigt
   ```

2. **Container starten**:
   ```bash
   docker-compose up -d --build
   ```

## Monitoring & Dashboard

Das Dashboard ist standardmÃ¤ÃŸig unter `http://localhost:11434/dashboard` erreichbar.

### Key Features im Dashboard:
- **Key Status**: Live-Status jedes Keys inklusive aktueller Penalty-Box Informationen (bei Rate-Limits).
- **Token Counter**: SchnellÃ¼bersicht der letzten 24h inklusive Trend-Analyse.
- **Recent Queries**: Live-Ansicht der letzten Anfragen mit der MÃ¶glichkeit, den Request-Body einzusehen.
- **Aggregated Stats**: StÃ¼ndlich aggregierte Daten nach Modell und IP-Adresse.

## API Endpunkte

- `/{path:path}`: Transparentes Proxying zur Ollama Cloud.
- `/dashboard`: Web-Interface.
- `/stats`: StÃ¼ndlich aggregierte Statistiken (JSON).
- `/stats/minute`: MinÃ¼tliche Statistiken fÃ¼r Charts (JSON).
- `/stats/24h`: Zusammenfassung der letzten 24 Stunden.
- `/health/keys`: Detaillierter Gesundheitszustand aller API-Keys.

## Nutzung

Der Proxy verhÃ¤lt sich wie eine lokale Ollama-Instanz.

```bash
curl http://localhost:11434/v1/chat/completions \
  -H "Authorization: Bearer dein_proxy_token" \
  -d '{
    "model": "llama3",
    "messages": [{"role": "user", "content": "Hallo!"}]
  }'
```

## Sicherheit
- Der Proxy leitet alle Pfade intelligent weiter (entfernt doppelte `/api` oder `/v1` PrÃ¤fixe automatisch).
- Request-Bodies werden lokal in `data/requests` als GZIP gespeichert.
- Die Datenbank `usage.db` befindet sich im `data` Ordner.